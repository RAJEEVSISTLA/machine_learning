{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9826587b-5bb5-4021-8dbc-a17ddc0fd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for Linear Regression...\n",
      "CV Mean RMSE: 0.8653085542331802, CV RMSE Std: 0.46879283271209293\n",
      "CV Mean R2: 0.5901627594638144, CV R2 Std: 0.3367900909286893\n",
      "\n",
      "Hyperparameter tuning for Ridge Regression...\n",
      "Best Ridge Regression model: {'alpha': 100}\n",
      "CV Mean RMSE: 0.26286051543572464, CV RMSE Std: 0.051213021815300214\n",
      "CV Mean R2: 0.886753553352975, CV R2 Std: 0.01932515888041925\n",
      "\n",
      "Hyperparameter tuning for Lasso Regression...\n",
      "Best Lasso Regression model: {'alpha': 0.1}\n",
      "CV Mean RMSE: 0.5124258169772276, CV RMSE Std: 0.10390199816102748\n",
      "CV Mean R2: 0.7808041454578976, CV R2 Std: 0.03322863547599528\n",
      "\n",
      "Hyperparameter tuning for KNN...\n",
      "Best KNN model: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "CV Mean RMSE: 0.3605547823079171, CV RMSE Std: 0.23021319749447408\n",
      "CV Mean R2: 0.8262177045452177, CV R2 Std: 0.16251222374733726\n",
      "\n",
      "Hyperparameter tuning for Decision Tree...\n",
      "Best Decision Tree model: {'max_depth': 20, 'min_samples_split': 2}\n",
      "CV Mean RMSE: 0.5057582384424929, CV RMSE Std: 0.35051313182996585\n",
      "CV Mean R2: 0.7559068564235236, CV R2 Std: 0.28652663372183146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:/Users/dhanu/OneDrive/Desktop/machine learning/gpt2 embeddings.xlsx\")\n",
    "\n",
    "# Drop any irrelevant columns, such as text or index columns\n",
    "data = data.drop(columns=['Equation', 'GPT2_Embedding'], errors='ignore')\n",
    "\n",
    "# Features and target variable\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data['output']     # Target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# List of regression models up to Decision Tree\n",
    "models = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Ridge Regression', Ridge()),\n",
    "    ('Lasso Regression', Lasso()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('Decision Tree', DecisionTreeRegressor())\n",
    "]\n",
    "\n",
    "# Function to calculate and return performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Cross-validation with 10 folds\n",
    "    cv_scores_rmse = cross_val_score(model, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "    cv_scores_r2 = cross_val_score(model, X, y, cv=10, scoring='r2')\n",
    "\n",
    "    # Compute mean and standard deviation of CV scores\n",
    "    rmse_mean = -cv_scores_rmse.mean()  # Convert negative RMSE to positive\n",
    "    rmse_std = cv_scores_rmse.std()\n",
    "    r2_mean = cv_scores_r2.mean()\n",
    "    r2_std = cv_scores_r2.std()\n",
    "\n",
    "    return rmse_mean, rmse_std, r2_mean, r2_std\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for the selected models\n",
    "param_grids = {\n",
    "    'Linear Regression': {},  # No hyperparameters for linear regression\n",
    "    'Ridge Regression': {'alpha': [0.1, 1, 10, 100]},\n",
    "    'Lasso Regression': {'alpha': [0.1, 1, 10]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 10, 15], 'weights': ['uniform', 'distance']},\n",
    "    'Decision Tree': {'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning and evaluation for each model\n",
    "for name, model in models:\n",
    "    print(f\"Hyperparameter tuning for {name}...\")\n",
    "    param_grid = param_grids.get(name, {})\n",
    "\n",
    "    # Skip models with no parameters to tune\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X, y)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best {name} model: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        best_model = model\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse_mean, rmse_std, r2_mean, r2_std = evaluate_model(best_model, X, y)\n",
    "\n",
    "    print(f\"CV Mean RMSE: {rmse_mean}, CV RMSE Std: {rmse_std}\")\n",
    "    print(f\"CV Mean R2: {r2_mean}, CV R2 Std: {r2_std}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7904380-1bf0-434f-83e0-7fe402ba3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for XGBoost...\n",
      "Best XGBoost model: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150, 'subsample': 0.7}\n",
      "CV Mean RMSE: 0.20369034762719052, CV RMSE Std: 0.045111077488425834\n",
      "CV Mean R2: 0.9128446817398072, CV R2 Std: 0.025940598537425915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:/Users/dhanu/OneDrive/Desktop/machine learning/gpt2 embeddings.xlsx\")\n",
    "\n",
    "# Drop any irrelevant columns, such as text or index columns\n",
    "data = data.drop(columns=['Equation', 'GPT2_Embedding'], errors='ignore')\n",
    "\n",
    "# Features and target variable\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data['output']     # Target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# XGBoost model\n",
    "model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Reduced hyperparameter tuning grid (fewer combinations)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],               # Fewer estimators\n",
    "    'learning_rate': [0.01, 0.1],             # Limited learning rates\n",
    "    'max_depth': [3, 5],                       # Shallower trees\n",
    "    'subsample': [0.7, 0.8],                   # Slightly lower subsample values\n",
    "    'colsample_bytree': [0.8, 1.0]             # Adjusted column sampling\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and evaluation with fewer cross-validation folds\n",
    "print(f\"Hyperparameter tuning for XGBoost...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)  # Reduced CV folds\n",
    "grid_search.fit(X, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best XGBoost model: {grid_search.best_params_}\")\n",
    "\n",
    "# Function to calculate and return performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Cross-validation with fewer folds\n",
    "    cv_scores_rmse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')  # Reduced folds\n",
    "    cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')  # Reduced folds\n",
    "\n",
    "    # Compute mean and standard deviation of CV scores\n",
    "    rmse_mean = -cv_scores_rmse.mean()  # Convert negative RMSE to positive\n",
    "    rmse_std = cv_scores_rmse.std()\n",
    "    r2_mean = cv_scores_r2.mean()\n",
    "    r2_std = cv_scores_r2.std()\n",
    "\n",
    "    return rmse_mean, rmse_std, r2_mean, r2_std\n",
    "\n",
    "# Evaluate the best model\n",
    "rmse_mean, rmse_std, r2_mean, r2_std = evaluate_model(best_model, X, y)\n",
    "\n",
    "print(f\"CV Mean RMSE: {rmse_mean}, CV RMSE Std: {rmse_std}\")\n",
    "print(f\"CV Mean R2: {r2_mean}, CV R2 Std: {r2_std}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0564e65-99c5-4e80-88f8-22c29c73e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for AdaBoost...\n",
      "Best AdaBoost model: {'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 100}\n",
      "CV Mean RMSE: 0.4930006583902896, CV RMSE Std: 0.03842519655156016\n",
      "CV Mean R2: 0.7909816830160323, CV R2 Std: 0.029356583648235506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:/Users/dhanu/OneDrive/Desktop/machine learning/gpt2 embeddings.xlsx\")\n",
    "\n",
    "# Drop any irrelevant columns, such as text or index columns\n",
    "data = data.drop(columns=['Equation', 'GPT2_Embedding'], errors='ignore')\n",
    "\n",
    "# Features and target variable\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data['output']     # Target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# AdaBoost model\n",
    "model = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Reduced options for faster execution\n",
    "    'learning_rate': [0.01, 0.1],  # Reduced learning rate options\n",
    "    'loss': ['linear', 'square']  # Reduced loss functions for faster testing\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and evaluation\n",
    "print(f\"Hyperparameter tuning for AdaBoost...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)  # Reduced cv folds to speed up\n",
    "grid_search.fit(X, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best AdaBoost model: {grid_search.best_params_}\")\n",
    "\n",
    "# Function to calculate and return performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Cross-validation with 5 folds to speed up (instead of 10)\n",
    "    cv_scores_rmse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "    # Compute mean and standard deviation of CV scores\n",
    "    rmse_mean = -cv_scores_rmse.mean()  # Convert negative RMSE to positive\n",
    "    rmse_std = cv_scores_rmse.std()\n",
    "    r2_mean = cv_scores_r2.mean()\n",
    "    r2_std = cv_scores_r2.std()\n",
    "\n",
    "    return rmse_mean, rmse_std, r2_mean, r2_std\n",
    "\n",
    "# Evaluate the best model\n",
    "rmse_mean, rmse_std, r2_mean, r2_std = evaluate_model(best_model, X, y)\n",
    "\n",
    "print(f\"CV Mean RMSE: {rmse_mean}, CV RMSE Std: {rmse_std}\")\n",
    "print(f\"CV Mean R2: {r2_mean}, CV R2 Std: {r2_std}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88db5b9-2101-4e00-a6df-7ab1aefdf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for Gradient Boosting...\n",
      "Best Gradient Boosting model: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.7}\n",
      "CV Mean RMSE: 0.2152094033469004, CV RMSE Std: 0.04459764028153108\n",
      "CV Mean R2: 0.907941296125659, CV R2 Std: 0.026326853456473676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:/Users/dhanu/OneDrive/Desktop/machine learning/gpt2 embeddings.xlsx\")\n",
    "\n",
    "# Drop any irrelevant columns, such as text or index columns\n",
    "data = data.drop(columns=['Equation', 'GPT2_Embedding'], errors='ignore')\n",
    "\n",
    "# Features and target variable\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data['output']     # Target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Gradient Boosting model\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Reduced options for faster execution\n",
    "    'learning_rate': [0.01, 0.1],  # Reduced learning rate options\n",
    "    'max_depth': [3, 5],  # Reduced depth for faster training\n",
    "    'subsample': [0.7, 0.8]  # Reduced subsample options\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and evaluation\n",
    "print(f\"Hyperparameter tuning for Gradient Boosting...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)  # Reduced cv folds to speed up\n",
    "grid_search.fit(X, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Gradient Boosting model: {grid_search.best_params_}\")\n",
    "\n",
    "# Function to calculate and return performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Cross-validation with 5 folds to speed up (instead of 10)\n",
    "    cv_scores_rmse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "    # Compute mean and standard deviation of CV scores\n",
    "    rmse_mean = -cv_scores_rmse.mean()  # Convert negative RMSE to positive\n",
    "    rmse_std = cv_scores_rmse.std()\n",
    "    r2_mean = cv_scores_r2.mean()\n",
    "    r2_std = cv_scores_r2.std()\n",
    "\n",
    "    return rmse_mean, rmse_std, r2_mean, r2_std\n",
    "\n",
    "# Evaluate the best model\n",
    "rmse_mean, rmse_std, r2_mean, r2_std = evaluate_model(best_model, X, y)\n",
    "\n",
    "print(f\"CV Mean RMSE: {rmse_mean}, CV RMSE Std: {rmse_std}\")\n",
    "print(f\"CV Mean R2: {r2_mean}, CV R2 Std: {r2_std}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aab5b2f-3a7f-4cc0-8b84-930434b86e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for Random Forest...\n",
      "Best Random Forest model: {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "CV Mean RMSE: 0.2507288136334071, CV RMSE Std: 0.060153943144596204\n",
      "CV Mean R2: 0.8924450121396921, CV R2 Std: 0.03486003338295441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:/Users/dhanu/OneDrive/Desktop/machine learning/gpt2 embeddings.xlsx\")\n",
    "\n",
    "# Drop any irrelevant columns, such as text or index columns\n",
    "data = data.drop(columns=['Equation', 'GPT2_Embedding'], errors='ignore')\n",
    "\n",
    "# Features and target variable\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data['output']     # Target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Reduced estimators for faster execution\n",
    "    'max_depth': [None, 10, 20],  # Reduced depth options\n",
    "    'min_samples_split': [2, 5],  # Limited to lower values for faster computation\n",
    "    'min_samples_leaf': [1, 2],   # Limited leaf size options\n",
    "    'bootstrap': [True]           # No need to test False for bootstrap\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and evaluation\n",
    "print(f\"Hyperparameter tuning for Random Forest...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)  # Reduced cv folds to speed up\n",
    "grid_search.fit(X, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Random Forest model: {grid_search.best_params_}\")\n",
    "\n",
    "# Function to calculate and return performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Cross-validation with 5 folds to speed up (instead of 10)\n",
    "    cv_scores_rmse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "    # Compute mean and standard deviation of CV scores\n",
    "    rmse_mean = -cv_scores_rmse.mean()  # Convert negative RMSE to positive\n",
    "    rmse_std = cv_scores_rmse.std()\n",
    "    r2_mean = cv_scores_r2.mean()\n",
    "    r2_std = cv_scores_r2.std()\n",
    "\n",
    "    return rmse_mean, rmse_std, r2_mean, r2_std\n",
    "\n",
    "# Evaluate the best model\n",
    "rmse_mean, rmse_std, r2_mean, r2_std = evaluate_model(best_model, X, y)\n",
    "\n",
    "print(f\"CV Mean RMSE: {rmse_mean}, CV RMSE Std: {rmse_std}\")\n",
    "print(f\"CV Mean R2: {r2_mean}, CV R2 Std: {r2_std}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbaa3620-bbca-43bc-af21-dbebeb44812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for SVR...\n",
      "Best SVR model: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "CV Mean RMSE: 0.16983354017960037, CV RMSE Std: 0.04492317753261408\n",
      "CV Mean R2: 0.9291665811010639, CV R2 Std: 0.015427305885617137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:/Users/dhanu/OneDrive/Desktop/machine learning/gpt2 embeddings.xlsx\")\n",
    "\n",
    "# Drop any irrelevant columns, such as text or index columns\n",
    "data = data.drop(columns=['Equation', 'GPT2_Embedding'], errors='ignore')\n",
    "\n",
    "# Features and target variable\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data['output']     # Target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# SVR model\n",
    "model = SVR()\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Reduced values for faster training\n",
    "    'kernel': ['linear', 'rbf'],  # Focus on common kernels\n",
    "    'gamma': ['scale'],  # Reduced gamma values (common choice)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and evaluation\n",
    "print(f\"Hyperparameter tuning for SVR...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)  # Reduced cv folds to speed up\n",
    "grid_search.fit(X, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best SVR model: {grid_search.best_params_}\")\n",
    "\n",
    "# Function to calculate and return performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Cross-validation with 5 folds to speed up (instead of 10)\n",
    "    cv_scores_rmse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "    # Compute mean and standard deviation of CV scores\n",
    "    rmse_mean = -cv_scores_rmse.mean()  # Convert negative RMSE to positive\n",
    "    rmse_std = cv_scores_rmse.std()\n",
    "    r2_mean = cv_scores_r2.mean()\n",
    "    r2_std = cv_scores_r2.std()\n",
    "\n",
    "    return rmse_mean, rmse_std, r2_mean, r2_std\n",
    "\n",
    "# Evaluate the best model\n",
    "rmse_mean, rmse_std, r2_mean, r2_std = evaluate_model(best_model, X, y)\n",
    "\n",
    "print(f\"CV Mean RMSE: {rmse_mean}, CV RMSE Std: {rmse_std}\")\n",
    "print(f\"CV Mean R2: {r2_mean}, CV R2 Std: {r2_std}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f603e-cb8a-4d22-8291-2e23534cf91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
